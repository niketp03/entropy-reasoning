/home/niket/miniconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Effective batch size: 32
/home/niket/miniconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Model initialized with looping configuration:
  - Total layers: 24
  - Early layers: 0 to 7
  - Loop layers: 8 to 12
  - Late layers: 13 to 23
  - Max loop count: 10
num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Map: 100%|███████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27 examples/s]
num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Map: 100%|███████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.76 examples/s]
***** Running training *****
  Num examples = 1
  Num epochs = 3
  Per-device batch size = 4
  Gradient accumulation steps = 8
  Total optimization steps = 0
  Using distillation: True
Evaluating: 100%|███████████████████████████████████████████████████████| 1/1 [00:00<00:00, 35.91it/s]
Evaluating: 100%|███████████████████████████████████████████████████████| 1/1 [00:00<00:00, 34.35it/s]
Evaluation loss: 3.4375
Evaluating: 100%|███████████████████████████████████████████████████████| 1/1 [00:00<00:00, 34.54it/s]
Evaluation loss: 4.0625
3it [00:09,  3.04s/it]                                                          | 0/1 [00:00<?, ?it/s]
Evaluation loss: 4.1562
